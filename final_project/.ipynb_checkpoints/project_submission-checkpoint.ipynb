{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features by data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "### features_list selects which features to include.\n",
    "features_list = ['poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances','bonus', \n",
    "                      'restricted_stock_deferred', 'deferred_income', 'total_stock_value', \n",
    "                      'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', \n",
    "                      'restricted_stock', 'director_fees', 'to_messages', 'from_poi_to_this_person', 'from_messages', \n",
    "                       'from_this_person_to_poi', 'shared_receipt_with_poi'\n",
    "                ]\n",
    "\n",
    "# Identifying columns with financial values\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'loan_advances','bonus', \n",
    "                      'restricted_stock_deferred', 'deferred_income', 'total_stock_value', \n",
    "                      'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', \n",
    "                      'restricted_stock', 'director_fees'\n",
    "                     ]\n",
    "\n",
    "# Identfying columns with numerical values\n",
    "features_with_count = ['to_messages', 'from_poi_to_this_person', 'from_messages', \n",
    "                       'from_this_person_to_poi', 'shared_receipt_with_poi'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "# Removing the 'TOTAL' value in data_dict because it is a column sum of salaries and doesn't belong to any single employee.\n",
    "del data_dict['TOTAL']\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any null-values present in the features chosen? \n",
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201955.0</td>\n",
       "      <td>2869717.0</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4175000.0</td>\n",
       "      <td>-126027.0</td>\n",
       "      <td>-3081055.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>13868.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>477.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>916197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-560222.0</td>\n",
       "      <td>-5104.0</td>\n",
       "      <td>5243487.0</td>\n",
       "      <td>56301.0</td>\n",
       "      <td>4046157.0</td>\n",
       "      <td>864523.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1757552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267102.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239671.0</td>\n",
       "      <td>260455.0</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>-82782.0</td>\n",
       "      <td>-201641.0</td>\n",
       "      <td>63014.0</td>\n",
       "      <td>129142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2    3          4         5          6   \\\n",
       "0  201955.0  2869717.0  4484442.0  0.0  4175000.0 -126027.0 -3081055.0   \n",
       "1       0.0   178980.0   182466.0  0.0        0.0       0.0        0.0   \n",
       "2     477.0        0.0   916197.0  0.0        0.0 -560222.0    -5104.0   \n",
       "3  267102.0  1295738.0  5634343.0  0.0  1200000.0       0.0 -1386055.0   \n",
       "4  239671.0   260455.0   827696.0  0.0   400000.0  -82782.0  -201641.0   \n",
       "\n",
       "           7         8          9          10         11         12   13  \\\n",
       "0   1729541.0   13868.0  1729541.0      152.0   304805.0   126027.0  0.0   \n",
       "1    257817.0    3486.0   257817.0        0.0        0.0        0.0  0.0   \n",
       "2   5243487.0   56301.0  4046157.0   864523.0        0.0  1757552.0  0.0   \n",
       "3  10623258.0   11200.0  6680544.0  2660303.0  1586055.0  3942714.0  0.0   \n",
       "4     63014.0  129142.0        0.0       69.0        0.0   145796.0  0.0   \n",
       "\n",
       "       14    15      16    17      18  \n",
       "0  2902.0  47.0  2195.0  65.0  1407.0  \n",
       "1     0.0   0.0     0.0   0.0     0.0  \n",
       "2   566.0  39.0    29.0   0.0   465.0  \n",
       "3     0.0   0.0     0.0   0.0     0.0  \n",
       "4     0.0   0.0     0.0   0.0     0.0  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming features into a df so that I won't have to remember to transform both features train and test.\n",
    "df_features = pd.DataFrame(features)\n",
    "print \"Any null-values present in the features chosen? \\n\", df_features.isnull().any()\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train and test for features and labels\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(df_features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importances using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking: \n",
      "  1.  feature: salary (0.220426513942)\n",
      "  2.  feature: deferral_payments (0.21197488041)\n",
      "  3.  feature: total_payments (0.132625994695)\n",
      "  4.  feature: loan_advances (0.106100795756)\n",
      "  5.  feature: bonus (0.105863661155)\n",
      "  6.  feature: restricted_stock_deferred (0.0757862826828)\n",
      "  7.  feature: deferred_income (0.0736811081639)\n",
      "  8.  feature: total_stock_value (0.0620731020005)\n",
      "  9.  feature: expenses (0.0114676611954)\n",
      "  10.  feature: exercised_stock_options (0.0)\n",
      "  11.  feature: other (0.0)\n",
      "  12.  feature: long_term_incentive (0.0)\n",
      "  13.  feature: restricted_stock (0.0)\n",
      "  14.  feature: director_fees (0.0)\n",
      "  15.  feature: to_messages (0.0)\n",
      "  16.  feature: from_poi_to_this_person (0.0)\n",
      "  17.  feature: from_messages (0.0)\n",
      "  18.  feature: from_this_person_to_poi (0.0)\n",
      "  19.  feature: shared_receipt_with_poi (0.0)\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# DecisionTree #\n",
    "################\n",
    "\n",
    "# Fitting the model\n",
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "# Feature Importances to identify which features have a high variance to be included in final model and which to exclude.\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print \"Feature Ranking: \"\n",
    "for i in range(len(importances)):\n",
    "    print \"  {}.  feature: {} ({})\".format(i+1, features_list[i+1], importances[indices[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature is bonus/salary and null-values replaced by 0\n",
    "# features_train['bonus_salary_ratio'] = features_train.iloc[:, 5] / features_train.iloc[:, 1]\n",
    "# features_train['bonus_salary_ratio'] = np.nan_to_num(features_train['bonus_salary_ratio'])\n",
    "\n",
    "# Repeat same feature engineering for test data\n",
    "# features_test['bonus_salary_ratio'] = features_test.iloc[:, 5] / features_test.iloc[:, 1]\n",
    "# features_test['bonus_salary_ratio'] = np.nan_to_num(features_test['bonus_salary_ratio'])\n",
    "\n",
    "# features_train.head()\n",
    "\n",
    "# New feature proved to make my models perform worse. See explanation at the Q&A section at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining feature_list based on feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['poi', 'salary', 'deferral_payments', 'total_payments', \n",
    "                'loan_advances', 'bonus', 'restricted_stock_deferred',\n",
    "                'deferred_income', 'total_stock_value', 'expenses'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.886363636364\n",
      "Precision score:  0.4\n",
      "Recall score:  0.5\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# GaussianNB #\n",
    "##############\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "# Classifier scores\n",
    "precision_score_gnb = precision_score(pred, labels_test)\n",
    "recall_score_gnb = recall_score(pred, labels_test)\n",
    "accuracy_score_gnb = accuracy_score(pred, labels_test)\n",
    "\n",
    "print \"Accuracy score: \", accuracy_score_gnb\n",
    "print \"Precision score: \", precision_score_gnb\n",
    "print \"Recall score: \", recall_score_gnb\n",
    "\n",
    "# Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.886363636364\n",
      "Precision score:  0.4\n",
      "Recall score:  0.5\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "# SVC #\n",
    "#######\n",
    "\n",
    "clf = SVC(random_state=42, kernel='sigmoid', C=57.9, gamma=0.059, class_weight='balanced')\n",
    "\n",
    "# Scaling both train and test features skipping 'poi' since it's a bool and the rest are financial values\n",
    "min_max_scaler = MinMaxScaler()\n",
    "features_train_scaled = min_max_scaler.fit_transform(features_train.iloc[:, 1:])\n",
    "features_test_scaled = min_max_scaler.fit_transform(features_test.iloc[:, 1:])\n",
    "\n",
    "\n",
    "# params = {'C': scipy.stats.expon(scale=100), \n",
    "#          'gamma': scipy.stats.expon(scale=.1), \n",
    "#          'kernel':['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "#          'class_weight': [None, 'balanced']\n",
    "#         }\n",
    "# clf_svc_rscv = RandomizedSearchCV(clf, param_distributions=params, cv=70, n_iter=50, scoring='precision', verbose=2, n_jobs=-1)\n",
    "# clf_svc_rscv.fit(features_train_scaled, labels_train)\n",
    "clf.fit(features_train_scaled, labels_train)\n",
    "\n",
    "# pred = clf.predict(features_test_scaled)\n",
    "\n",
    "# Classifier scores\n",
    "precision_score_svc = precision_score(pred, labels_test)\n",
    "recall_score_svc = recall_score(pred, labels_test)\n",
    "accuracy_score_svc = accuracy_score(pred, labels_test)\n",
    "\n",
    "print \"Accuracy score: \", accuracy_score_svc\n",
    "print \"Precision score: \", precision_score_svc\n",
    "print \"Recall score: \", recall_score_svc\n",
    "\n",
    "# print clf_svc_rscv.best_params_\n",
    "# print clf_svc_rscv.best_score_\n",
    "\n",
    "# parameters that return the best recall score:\n",
    "# {'kernel': 'sigmoid', 'C': 22.124794209078111, 'gamma': 0.38710403019966072, 'class_weight': 'balanced'}\n",
    "# 0.33\n",
    "\n",
    "# parameters that return the best precision score:\n",
    "# {'kernel': 'sigmoid', 'C': 57.914218875973347, 'gamma': 0.059626099388516422, 'class_weight': 'balanced'}\n",
    "# 0.235\n",
    "\n",
    "# Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1, 'min_samples_split': 5, 'max_depth': 34, 'min_samples_leaf': 1}\n",
      "0.21\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Random Forest #\n",
    "#################\n",
    "\n",
    "# Fitting the model\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=1, min_samples_leaf=2, min_samples_split=2, max_depth=31)\n",
    "\n",
    "# RandomizedsearchCV to find optimal hyper params\n",
    "#params = {\n",
    "#          'n_estimators':np.arange(1, 5, 1),\n",
    "#          'min_samples_leaf':np.arange(1, 5, 1),\n",
    "#          'min_samples_split':np.arange(2, 20, 1),\n",
    "#          'max_depth':np.arange(1, 40, 1),\n",
    "#         }\n",
    "\n",
    "#clf_rf_rscv = RandomizedSearchCV(clf, cv=70, n_iter=50, param_distributions=params, scoring='recall', verbose=2, n_jobs=-1)\n",
    "#clf_rf_rscv.fit(features_train, labels_train)\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "\n",
    "# print clf_rf_rscv.best_params_\n",
    "# print clf_rf_rscv.best_score_\n",
    "\n",
    "# Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "# best results from randomizedsearchCV using \"recall\" scoring:\n",
    "# {'n_estimators': 1, 'min_samples_split': 2, 'max_depth': 31, 'min_samples_leaf': 2}\n",
    "# 0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  [relevant rubric items: “data exploration”, “outlier investigation”]\n",
    "\n",
    ">Machine learning is powerful at predicting whether a certain outcome is likely to happen (classification) or continuous numbers (regression). In this example where we are asked to predict that a person is a POI (classification) and we have features such as salary, bonus, stock (financial) as well as how many emails they have sent/received (count) we can use such features to learn if these help us predict whether people are POIs or not. As for outliers, I have only removed one due to the scarcity of data to begin with. The one I have removed is the column sum in the PDF of Enron employees' salaries because that's not a feature of an employee.\n",
    "\n",
    "2.What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]\n",
    "\n",
    ">As part of the EDA I looked at feature importances to understand which features were important and which weren't useful to include in my machine learning algorithms. I took all features which had an importance > 0, so that means the following 9 features: 'poi', 'salary', 'deferral_payments', 'total_payments','loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses'. As for the feature importances scores for the features I have used they are as follows:   \n",
    "  1. feature: salary (0.220426513942)\n",
    "  2. feature: deferral_payments (0.21197488041)\n",
    "  3. feature: total_payments (0.132625994695)\n",
    "  4. feature: loan_advances (0.106100795756)\n",
    "  5. feature: bonus (0.105863661155)\n",
    "  6. feature: restricted_stock_deferred (0.0757862826828)\n",
    "  7. feature: deferred_income (0.0736811081639)\n",
    "  8. feature: total_stock_value (0.0620731020005)\n",
    "  9. feature: expenses (0.0114676611954)\n",
    "\n",
    "> I have scaled the numerical features in my SVC model using MinMaxScaler to easier be able to compare the different financial measurements on a scale of 0 to 1.\n",
    "> I have created my own feature bonus_salary_ratio which is bonus / salary based on the rationale that someone who has a high salary (top correlated feature with a POI) is likely also to have a high bonus however it made my models perform worse, especially GaussianNB due to the large amount of bonuses AND salaries which both were 0's so I was dividing 0 by 0, or some bonuses being negative leading to a -inf when divided by salary.\n",
    "\n",
    ">As mentioned earlier I have decided to include any feature with a score > 0.\n",
    "\n",
    "3.What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]\n",
    "\n",
    "> I ended it up using the GaussianNB because it returned a precision of .4 and recall of .5. which was the highest scores out of them all. I tried SVC and Random Forest, but SVC performed the worse and I suspect it's due to the scarcity of data. I fine-tuned Random Forest using RandomizedSearchCV but couldn't get a precision above .3 for both precision and recall.\n",
    "\n",
    "4.What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).  [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]\n",
    "\n",
    "> Tuning the parameters of an algorithm is really customising the model to match your dataset. For some of the parameters such as min_samples_split there is a trade-off between performance and accuracy: a high sample_split means you are avoiding over-fitting whereas a too high value means you are underfitting. Likewise with the learning_rate, if you give it too high a value you risk it might miss the optimal point whereas if it's too low it will take too long to converge and reach the local minima. For Random Forests, I've tuned the main parameters using RandomizedSearchCV but the best model didn't make it to the .3 precisio/recall scores. Below were the params and their ranges which I used for RandomizedSearchCV for Random Forest:\n",
    "\n",
    ">params = {\n",
    "          'n_estimators':np.arange(1, 5, 1),\n",
    "          'min_samples_leaf':np.arange(1, 5, 1),\n",
    "          'min_samples_split':np.arange(2, 20, 1),\n",
    "          'max_depth':np.arange(1, 40, 1),\n",
    "         }\n",
    "         \n",
    "> and for SVC I have used the following params:\n",
    "\n",
    "> params = {'C': scipy.stats.expon(scale=100), \n",
    "          'gamma': scipy.stats.expon(scale=.1), \n",
    "          'kernel':['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "          'class_weight': [None, 'balanced']\n",
    "         }\n",
    "> if my GaussianNB classifier weren't the top performing model I would have fine-tuned my model using RandomizedSearchCV like I did for Random Forest and SVC to find the optimal parameters to use in my model.\n",
    "\n",
    "5.What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric items: “discuss validation”, “validation strategy”]\n",
    "\n",
    "> Validation, also known as cross-validation. It is used to prevent over-fitting to the training data. If you don't use cross-validation you risk overfitting your model to the training dataset which means it won't be able to perform well on un-seen new data because it is unable to generalise well. CV works by splitting the training dataset into smaller sets which the model is evaluated on and for each fold it will then return the score average accuracy score from all of the folds. CV is especially important with imbalanced classes as it increases the probability that your CV folds are more representative of the data.\n",
    "\n",
    "6.Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
