{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajawad/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "import time\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features by data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### features_list selects which features to include.\n",
    "features_list = ['poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances','bonus', \n",
    "                      'restricted_stock_deferred', 'deferred_income', 'total_stock_value', \n",
    "                      'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', \n",
    "                      'restricted_stock', 'director_fees', 'to_messages', 'from_poi_to_this_person', 'from_messages', \n",
    "                       'from_this_person_to_poi', 'shared_receipt_with_poi'\n",
    "                ]\n",
    "\n",
    "# Identifying columns with financial values\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'loan_advances','bonus', \n",
    "                      'restricted_stock_deferred', 'deferred_income', 'total_stock_value', \n",
    "                      'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', \n",
    "                      'restricted_stock', 'director_fees'\n",
    "                     ]\n",
    "\n",
    "# Identfying columns with numerical values\n",
    "features_with_count = ['to_messages', 'from_poi_to_this_person', 'from_messages', \n",
    "                       'from_this_person_to_poi', 'shared_receipt_with_poi'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METTS MARK\n",
      "BAXTER JOHN C\n",
      "ELLIOTT STEVEN\n",
      "CORDES WILLIAM R\n",
      "HANNON KEVIN P\n",
      "MORDAUNT KRISTINA M\n",
      "MEYER ROCKFORD G\n",
      "MCMAHON JEFFREY\n",
      "HORTON STANLEY C\n",
      "PIPER GREGORY F\n",
      "HUMPHREY GENE E\n",
      "UMANOFF ADAM S\n",
      "BLACHMAN JEREMY M\n",
      "SUNDE MARTIN\n",
      "GIBBS DANA R\n",
      "LOWRY CHARLES P\n",
      "COLWELL WESLEY\n",
      "MULLER MARK S\n",
      "JACKSON CHARLENE R\n",
      "WESTFAHL RICHARD K\n",
      "WALTERS GARETH W\n",
      "WALLS JR ROBERT H\n",
      "KITCHEN LOUISE\n",
      "CHAN RONNIE\n",
      "BELFER ROBERT\n",
      "SHANKMAN JEFFREY A\n",
      "WODRASKA JOHN\n",
      "BERGSIEKER RICHARD P\n",
      "URQUHART JOHN A\n",
      "BIBI PHILIPPE A\n",
      "RIEKER PAULA H\n",
      "WHALEY DAVID A\n",
      "BECK SALLY W\n",
      "HAUG DAVID L\n",
      "ECHOLS JOHN B\n",
      "MENDELSOHN JOHN\n",
      "HICKERSON GARY J\n",
      "CLINE KENNETH W\n",
      "LEWIS RICHARD\n",
      "HAYES ROBERT E\n",
      "MCCARTY DANNY J\n",
      "KOPPER MICHAEL J\n",
      "LEFF DANIEL P\n",
      "LAVORATO JOHN J\n",
      "BERBERIAN DAVID\n",
      "DETMERING TIMOTHY J\n",
      "WAKEHAM JOHN\n",
      "POWERS WILLIAM\n",
      "GOLD JOSEPH\n",
      "BANNANTINE JAMES M\n",
      "DUNCAN JOHN H\n",
      "SHAPIRO RICHARD S\n",
      "SHERRIFF JOHN R\n",
      "SHELBY REX\n",
      "LEMAISTRE CHARLES\n",
      "DEFFNER JOSEPH M\n",
      "KISHKILL JOSEPH G\n",
      "WHALLEY LAWRENCE G\n",
      "MCCONNELL MICHAEL S\n",
      "PIRO JIM\n",
      "DELAINEY DAVID W\n",
      "SULLIVAN-SHAKLOVITZ COLLEEN\n",
      "WROBEL BRUCE\n",
      "LINDHOLM TOD A\n",
      "MEYER JEROME J\n",
      "LAY KENNETH L\n",
      "BUTTS ROBERT H\n",
      "OLSON CINDY K\n",
      "MCDONALD REBECCA\n",
      "CUMBERLAND MICHAEL S\n",
      "GAHN ROBERT S\n",
      "MCCLELLAN GEORGE\n",
      "HERMANN ROBERT J\n",
      "SCRIMSHAW MATTHEW\n",
      "GATHMANN WILLIAM D\n",
      "HAEDICKE MARK E\n",
      "BOWEN JR RAYMOND M\n",
      "GILLIS JOHN\n",
      "FITZGERALD JAY L\n",
      "MORAN MICHAEL P\n",
      "REDMOND BRIAN L\n",
      "BAZELIDES PHILIP J\n",
      "BELDEN TIMOTHY N\n",
      "DURAN WILLIAM D\n",
      "THORN TERENCE H\n",
      "FASTOW ANDREW S\n",
      "FOY JOE\n",
      "CALGER CHRISTOPHER F\n",
      "RICE KENNETH D\n",
      "KAMINSKI WINCENTY J\n",
      "LOCKHART EUGENE E\n",
      "COX DAVID\n",
      "OVERDYKE JR JERE C\n",
      "PEREIRA PAULO V. FERRAZ\n",
      "STABLER FRANK\n",
      "SKILLING JEFFREY K\n",
      "BLAKE JR. NORMAN P\n",
      "SHERRICK JEFFREY B\n",
      "PRENTICE JAMES\n",
      "GRAY RODNEY\n",
      "PICKERING MARK R\n",
      "THE TRAVEL AGENCY IN THE PARK\n",
      "NOLES JAMES L\n",
      "KEAN STEVEN J\n",
      "TOTAL\n",
      "FOWLER PEGGY\n",
      "WASAFF GEORGE\n",
      "WHITE JR THOMAS E\n",
      "CHRISTODOULOU DIOMEDES\n",
      "ALLEN PHILLIP K\n",
      "SHARP VICTORIA T\n",
      "JAEDICKE ROBERT\n",
      "WINOKUR JR. HERBERT S\n",
      "BROWN MICHAEL\n",
      "BADUM JAMES P\n",
      "HUGHES JAMES A\n",
      "REYNOLDS LAWRENCE\n",
      "DIMICHELE RICHARD G\n",
      "BHATNAGAR SANJAY\n",
      "CARTER REBECCA C\n",
      "BUCHANAN HAROLD G\n",
      "YEAP SOON\n",
      "MURRAY JULIA H\n",
      "GARLAND C KEVIN\n",
      "DODSON KEITH\n",
      "YEAGER F SCOTT\n",
      "HIRKO JOSEPH\n",
      "DIETRICH JANET R\n",
      "DERRICK JR. JAMES V\n",
      "FREVERT MARK A\n",
      "PAI LOU L\n",
      "BAY FRANKLIN R\n",
      "HAYSLETT RODERICK J\n",
      "FUGH JOHN L\n",
      "FALLON JAMES B\n",
      "KOENIG MARK E\n",
      "SAVAGE FRANK\n",
      "IZZO LAWRENCE L\n",
      "TILNEY ELIZABETH A\n",
      "MARTIN AMANDA K\n",
      "BUY RICHARD B\n",
      "GRAMM WENDY L\n",
      "CAUSEY RICHARD A\n",
      "TAYLOR MITCHELL S\n",
      "DONAHUE JR JEFFREY M\n",
      "GLISAN JR BEN F\n"
     ]
    }
   ],
   "source": [
    "# Ensuring that all keys refer to Enron employees\n",
    "for k, v in data_dict.iteritems():\n",
    "    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in the dataset: 146\n"
     ]
    }
   ],
   "source": [
    "# Shape of dataset\n",
    "print \"Rows in the dataset:\", len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POIs in the dataset:  18\n",
      "Non-POIs in the dataset:  123\n"
     ]
    }
   ],
   "source": [
    "# POIs and non-POIs in the dataset\n",
    "poi_num = 0\n",
    "non_poi_num = 0\n",
    "for poi in labels:\n",
    "    if poi == 1.0:\n",
    "        poi_num += 1\n",
    "    else:\n",
    "        non_poi_num += 1\n",
    "\n",
    "# Imbalanced classes of POIs - more Non-POIs than POIs.\n",
    "print \"POIs in the dataset: \", poi_num\n",
    "print \"Non-POIs in the dataset: \", non_poi_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAP SOON :  NaN\n",
      "WROBEL BRUCE :  NaN\n",
      "WODRASKA JOHN :  NaN\n",
      "WINOKUR JR. HERBERT S :  NaN\n",
      "WHALEY DAVID A :  NaN\n",
      "WALTERS GARETH W :  NaN\n",
      "WAKEHAM JOHN :  NaN\n",
      "URQUHART JOHN A :  NaN\n",
      "THE TRAVEL AGENCY IN THE PARK :  NaN\n",
      "SHERRICK JEFFREY B :  NaN\n",
      "SCRIMSHAW MATTHEW :  NaN\n",
      "SAVAGE FRANK :  NaN\n",
      "PRENTICE JAMES :  NaN\n",
      "POWERS WILLIAM :  NaN\n",
      "PIRO JIM :  NaN\n",
      "PEREIRA PAULO V. FERRAZ :  NaN\n",
      "NOLES JAMES L :  NaN\n",
      "MORAN MICHAEL P :  NaN\n",
      "MEYER ROCKFORD G :  NaN\n",
      "MEYER JEROME J :  NaN\n",
      "MENDELSOHN JOHN :  NaN\n",
      "MCDONALD REBECCA :  NaN\n",
      "MCCARTY DANNY J :  NaN\n",
      "LOWRY CHARLES P :  NaN\n",
      "LOCKHART EUGENE E :  NaN\n",
      "LEWIS RICHARD :  NaN\n",
      "LEMAISTRE CHARLES :  NaN\n",
      "JAEDICKE ROBERT :  NaN\n",
      "HUGHES JAMES A :  NaN\n",
      "HORTON STANLEY C :  NaN\n",
      "HIRKO JOSEPH :  NaN\n",
      "HAYSLETT RODERICK J :  NaN\n",
      "HAYES ROBERT E :  NaN\n",
      "HAUG DAVID L :  NaN\n",
      "GRAMM WENDY L :  NaN\n",
      "GILLIS JOHN :  NaN\n",
      "GIBBS DANA R :  NaN\n",
      "GATHMANN WILLIAM D :  NaN\n",
      "FUGH JOHN L :  NaN\n",
      "FOY JOE :  NaN\n",
      "FOWLER PEGGY :  NaN\n",
      "DUNCAN JOHN H :  NaN\n",
      "CORDES WILLIAM R :  NaN\n",
      "CLINE KENNETH W :  NaN\n",
      "CHRISTODOULOU DIOMEDES :  NaN\n",
      "CHAN RONNIE :  NaN\n",
      "BROWN MICHAEL :  NaN\n",
      "BLAKE JR. NORMAN P :  NaN\n",
      "BHATNAGAR SANJAY :  NaN\n",
      "BELFER ROBERT :  NaN\n",
      "BADUM JAMES P :  NaN\n",
      "TOTAL :  26704229\n",
      "SKILLING JEFFREY K :  1111258\n",
      "LAY KENNETH L :  1072321\n",
      "FREVERT MARK A :  1060932\n",
      "PICKERING MARK R :  655037\n",
      "WHALLEY LAWRENCE G :  510364\n",
      "DERRICK JR. JAMES V :  492375\n",
      "FASTOW ANDREW S :  440698\n",
      "SHERRIFF JOHN R :  428780\n",
      "RICE KENNETH D :  420636\n",
      "CAUSEY RICHARD A :  415189\n",
      "KEAN STEVEN J :  404338\n",
      "HAEDICKE MARK E :  374125\n",
      "MCMAHON JEFFREY :  370448\n",
      "METTS MARK :  365788\n",
      "DELAINEY DAVID W :  365163\n",
      "MCCONNELL MICHAEL S :  365038\n",
      "WALLS JR ROBERT H :  357091\n",
      "MARTIN AMANDA K :  349487\n",
      "LAVORATO JOHN J :  339288\n",
      "BUY RICHARD B :  330546\n",
      "OLSON CINDY K :  329078\n",
      "WHITE JR THOMAS E :  317543\n",
      "COX DAVID :  314288\n",
      "KOENIG MARK E :  309946\n",
      "FALLON JAMES B :  304588\n",
      "SHANKMAN JEFFREY A :  304110\n",
      "UMANOFF ADAM S :  288589\n",
      "JACKSON CHARLENE R :  288558\n",
      "COLWELL WESLEY :  288542\n",
      "DONAHUE JR JEFFREY M :  278601\n",
      "BOWEN JR RAYMOND M :  278601\n",
      "KAMINSKI WINCENTY J :  275101\n",
      "GLISAN JR BEN F :  274975\n",
      "LEFF DANIEL P :  273746\n",
      "GOLD JOSEPH :  272880\n",
      "KITCHEN LOUISE :  271442\n",
      "SHAPIRO RICHARD S :  269076\n",
      "BAXTER JOHN C :  267102\n",
      "MORDAUNT KRISTINA M :  267093\n",
      "TAYLOR MITCHELL S :  265214\n",
      "MCCLELLAN GEORGE :  263413\n",
      "DIMICHELE RICHARD G :  262788\n",
      "HERMANN ROBERT J :  262663\n",
      "PAI LOU L :  261879\n",
      "CARTER REBECCA C :  261809\n",
      "BUTTS ROBERT H :  261516\n",
      "WASAFF GEORGE :  259996\n",
      "SUNDE MARTIN :  257486\n",
      "MULLER MARK S :  251654\n",
      "DIETRICH JANET R :  250100\n",
      "RIEKER PAULA H :  249201\n",
      "BLACHMAN JEREMY M :  248546\n",
      "SHARP VICTORIA T :  248146\n",
      "BUCHANAN HAROLD G :  248017\n",
      "TILNEY ELIZABETH A :  247338\n",
      "HANNON KEVIN P :  243293\n",
      "CALGER CHRISTOPHER F :  240189\n",
      "BAY FRANKLIN R :  239671\n",
      "STABLER FRANK :  239502\n",
      "LINDHOLM TOD A :  236457\n",
      "GARLAND C KEVIN :  231946\n",
      "BECK SALLY W :  231330\n",
      "MURRAY JULIA H :  229284\n",
      "KOPPER MICHAEL J :  224305\n",
      "THORN TERENCE H :  222093\n",
      "DODSON KEITH :  221003\n",
      "BERBERIAN DAVID :  216582\n",
      "BELDEN TIMOTHY N :  213999\n",
      "BIBI PHILIPPE A :  213625\n",
      "SHELBY REX :  211844\n",
      "HICKERSON GARY J :  211788\n",
      "DURAN WILLIAM D :  210692\n",
      "DETMERING TIMOTHY J :  210500\n",
      "DEFFNER JOSEPH M :  206121\n",
      "ALLEN PHILLIP K :  201955\n",
      "FITZGERALD JAY L :  199157\n",
      "PIPER GREGORY F :  197091\n",
      "GAHN ROBERT S :  192008\n",
      "BERGSIEKER RICHARD P :  187922\n",
      "CUMBERLAND MICHAEL S :  184899\n",
      "ECHOLS JOHN B :  182245\n",
      "KISHKILL JOSEPH G :  174246\n",
      "ELLIOTT STEVEN :  170941\n",
      "SULLIVAN-SHAKLOVITZ COLLEEN :  162779\n",
      "YEAGER F SCOTT :  158403\n",
      "HUMPHREY GENE E :  130724\n",
      "REDMOND BRIAN L :  96840\n",
      "OVERDYKE JR JERE C :  94941\n",
      "IZZO LAWRENCE L :  85274\n",
      "BAZELIDES PHILIP J :  80818\n",
      "REYNOLDS LAWRENCE :  76399\n",
      "WESTFAHL RICHARD K :  63744\n",
      "GRAY RODNEY :  6615\n",
      "BANNANTINE JAMES M :  477\n"
     ]
    }
   ],
   "source": [
    "mat_dict = {}\n",
    "for key in data_dict:\n",
    "    mat_dict[key] = data_dict[key]['salary']\n",
    "    \n",
    "for key, value in sorted(mat_dict.iteritems(), key=lambda (k,v): (v, k), reverse=True):\n",
    "   print key, \": \", value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing keys 'TOTAL', 'THE TRAVEL AGENCY IN THE PARK', 'BANNANTINE JAMES M' and 'GRAY RODNEY' in data_dict because they are either not employees or in the case of Gray and Bannantine they are outliers.\n",
    "del data_dict['TOTAL']\n",
    "del data_dict['THE TRAVEL AGENCY IN THE PARK']\n",
    "del data_dict['BANNANTINE JAMES M']\n",
    "del data_dict['GRAY RODNEY']\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any null-values present in the features chosen? \n",
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201955.0</td>\n",
       "      <td>2869717.0</td>\n",
       "      <td>4484442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4175000.0</td>\n",
       "      <td>-126027.0</td>\n",
       "      <td>-3081055.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>13868.0</td>\n",
       "      <td>1729541.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>304805.0</td>\n",
       "      <td>126027.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>178980.0</td>\n",
       "      <td>182466.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>257817.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>267102.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239671.0</td>\n",
       "      <td>260455.0</td>\n",
       "      <td>827696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>-82782.0</td>\n",
       "      <td>-201641.0</td>\n",
       "      <td>63014.0</td>\n",
       "      <td>129142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145796.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80818.0</td>\n",
       "      <td>684694.0</td>\n",
       "      <td>860136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599641.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1599641.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>93750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2    3          4         5          6   \\\n",
       "0  201955.0  2869717.0  4484442.0  0.0  4175000.0 -126027.0 -3081055.0   \n",
       "1       0.0   178980.0   182466.0  0.0        0.0       0.0        0.0   \n",
       "2  267102.0  1295738.0  5634343.0  0.0  1200000.0       0.0 -1386055.0   \n",
       "3  239671.0   260455.0   827696.0  0.0   400000.0  -82782.0  -201641.0   \n",
       "4   80818.0   684694.0   860136.0  0.0        0.0       0.0        0.0   \n",
       "\n",
       "           7         8          9          10         11         12   13  \\\n",
       "0   1729541.0   13868.0  1729541.0      152.0   304805.0   126027.0  0.0   \n",
       "1    257817.0    3486.0   257817.0        0.0        0.0        0.0  0.0   \n",
       "2  10623258.0   11200.0  6680544.0  2660303.0  1586055.0  3942714.0  0.0   \n",
       "3     63014.0  129142.0        0.0       69.0        0.0   145796.0  0.0   \n",
       "4   1599641.0       0.0  1599641.0      874.0    93750.0        0.0  0.0   \n",
       "\n",
       "       14    15      16    17      18  \n",
       "0  2902.0  47.0  2195.0  65.0  1407.0  \n",
       "1     0.0   0.0     0.0   0.0     0.0  \n",
       "2     0.0   0.0     0.0   0.0     0.0  \n",
       "3     0.0   0.0     0.0   0.0     0.0  \n",
       "4     0.0   0.0     0.0   0.0     0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming features into a df so that I won't have to remember to transform\n",
    "# both features train and test.\n",
    "df_features = pd.DataFrame(features)\n",
    "print \"Any null-values present in the features chosen? \\n\", df_features.isnull().any()\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train and test for features and labels\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(df_features, labels, test_size=0.3, random_state=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importances using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 features in Feature Importances.\n",
      "Feature ranking: \n",
      "  1.  feature: salary (0.21274406496)\n",
      "  2.  feature: deferral_payments (0.189106111008)\n",
      "  3.  feature: total_payments (0.177991452991)\n",
      "  4.  feature: loan_advances (0.0751856363847)\n",
      "  5.  feature: bonus (0.0660231271996)\n",
      "  6.  feature: restricted_stock_deferred (0.0)\n",
      "  7.  feature: deferred_income (0.0)\n",
      "  8.  feature: total_stock_value (0.0)\n",
      "  9.  feature: expenses (0.0)\n",
      "  10.  feature: exercised_stock_options (0.0)\n",
      "  11.  feature: other (0.0)\n",
      "  12.  feature: long_term_incentive (0.0)\n",
      "  13.  feature: restricted_stock (0.0)\n",
      "  14.  feature: director_fees (0.0)\n",
      "  15.  feature: to_messages (0.0)\n",
      "  16.  feature: from_poi_to_this_person (0.0)\n",
      "  17.  feature: from_messages (0.0)\n",
      "  18.  feature: from_this_person_to_poi (0.0)\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Feature Importances #\n",
    "#######################\n",
    "\n",
    "# Fitting the model\n",
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "# Feature Importances to identify which features have a high variance to be included\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print len(importances), \"features in Feature Importances.\" \n",
    "print \"Feature ranking: \"\n",
    "for i in range(1, len(importances), 1):\n",
    "    print \"  {}.  feature: {} ({})\".format(i, features_list[i], importances[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40      0.000000e+00\n",
      "24    -1.797693e+308\n",
      "25      0.000000e+00\n",
      "127     0.000000e+00\n",
      "76      0.000000e+00\n",
      "Name: bonus_salary_ratio, dtype: float64\n",
      "Are null-values present in new feature? False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajawad/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/ajawad/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/ajawad/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/ajawad/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# New feature is bonus/salary and null-values replaced by 0\n",
    "features_train['bonus_salary_ratio'] = features_train.loc[:, 5] / features_train.loc[:, 1]\n",
    "features_train['bonus_salary_ratio'] = np.nan_to_num(features_train['bonus_salary_ratio'])\n",
    "\n",
    "# Repeat same feature engineering for test data\n",
    "features_test['bonus_salary_ratio'] = features_test.loc[:, 5] / features_test.loc[:, 1]\n",
    "features_test['bonus_salary_ratio'] = np.nan_to_num(features_test['bonus_salary_ratio'])\n",
    "\n",
    "# Explore the new feature created\n",
    "print features_train['bonus_salary_ratio'].head()\n",
    "print \"Are null-values present in new feature?\", features_train['bonus_salary_ratio'].isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015698</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.914658</td>\n",
       "      <td>0.880984</td>\n",
       "      <td>0.136770</td>\n",
       "      <td>0.343377</td>\n",
       "      <td>0.142375</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019927</td>\n",
       "      <td>0.014391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.914658</td>\n",
       "      <td>0.957214</td>\n",
       "      <td>0.015102</td>\n",
       "      <td>0.072188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137839</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.205035</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015698</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.914658</td>\n",
       "      <td>0.989110</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015698</td>\n",
       "      <td>0.100674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.914658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106018</td>\n",
       "      <td>0.216543</td>\n",
       "      <td>0.121083</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.565383</td>\n",
       "      <td>0.068295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179914</td>\n",
       "      <td>0.674877</td>\n",
       "      <td>0.717624</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1    2        3         4         5         6         7   \\\n",
       "0  0.015698  0.002044  0.0  0.04375  0.914658  0.880984  0.136770  0.343377   \n",
       "1  0.015698  0.000000  0.0  0.00000  0.000000  1.000000  0.004753  0.000000   \n",
       "2  0.019927  0.014391  0.0  0.15000  0.914658  0.957214  0.015102  0.072188   \n",
       "3  0.015698  0.002208  0.0  0.00000  0.914658  0.989110  0.000897  0.999532   \n",
       "4  0.015698  0.100674  0.0  1.00000  0.914658  1.000000  0.106018  0.216543   \n",
       "\n",
       "         8         9         10        11        12        13        14  \\\n",
       "0  0.142375  0.001251  0.000000  0.121151  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.044852  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.009821  0.000000  0.047301  0.000000  0.137839  0.454545   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.322242  0.000000  0.000000   \n",
       "4  0.121083  0.000150  0.565383  0.068295  0.000000  0.569155  1.000000   \n",
       "\n",
       "         15        16        17   18  \n",
       "0  0.000000  0.000000  0.000000  1.0  \n",
       "1  0.000000  0.000000  0.000000  0.0  \n",
       "2  0.002784  0.018062  0.205035  1.0  \n",
       "3  0.000000  0.000000  0.000000  1.0  \n",
       "4  0.179914  0.674877  0.717624  1.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature scaling using MinMaxScaling since numerical values span positive and negative\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Reshaping feature because it's a 1D-array\n",
    "#bonus_salary_ratio_train_reshaped = features_train['bonus_salary_ratio'].values.reshape(-1, 1)\n",
    "#bonus_salary_ratio_test_reshaped = features_test['bonus_salary_ratio'].values.reshape(-1, 1)\n",
    "\n",
    "# Scaling new feature due to presence of negative values\n",
    "#features_train = min_max_scaler.fit_transform(features_train)\n",
    "#features_test = min_max_scaler.fit_transform(features_test)\n",
    "\n",
    "# Slicing all rows but ignoring first column since it's a bool (\"poi\")\n",
    "features_train_scaled = min_max_scaler.fit_transform(features_train.iloc[:, 1:])\n",
    "features_test_scaled = min_max_scaler.fit_transform(features_test.iloc[:, 1:])\n",
    "\n",
    "# Transforming both scaled train and test from np arrays to pandas dataframes\n",
    "features_train_scaled = pd.DataFrame(features_train_scaled)\n",
    "features_test_scaled = pd.DataFrame(features_test_scaled)\n",
    "\n",
    "features_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking: \n",
      "  1.  feature: salary (0.21274406496)\n",
      "  2.  feature: deferral_payments (0.177991452991)\n",
      "  3.  feature: total_payments (0.165550527903)\n",
      "  4.  feature: loan_advances (0.0826807716413)\n",
      "  5.  feature: bonus (0.0751856363847)\n",
      "  6.  feature: bonus_salary_ratio (0.0660231271996)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-fa6f6db7ee72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Feature ranking: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"  {}.  feature: {} ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Refining features_list to only include features with >0 importance \n",
    "#and to include the new feature in features_list\n",
    "\n",
    "features_list = ['poi', 'salary', 'deferral_payments','total_payments', \n",
    "                'loan_advances', 'bonus']\n",
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "# Feature Importances to see whether new feature created has any importance.\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "print \"Feature ranking: \"\n",
    "for i in range(1, len(importances), 1):\n",
    "    print \"  {}.  feature: {} ({})\".format(i, features_list[i], importances[indices[i]])\n",
    "    \n",
    "    # 6.  feature: bonus_salary_ratio (0.0660231271996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up CV using stratifiedshufflesplit due to class imbalance of POI.\n",
    "# cross_validator to be used as cv parameter for grid/randomizedsearchcv.\n",
    "cv = StratifiedShuffleSplit(n_splits=100, test_size=0.1, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  1.0\n",
      "Recall score:  0.883720930233\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# Naive Bayes #\n",
    "###############\n",
    "\n",
    "def fitGNB():\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(features_train_scaled, labels_train)\n",
    "\n",
    "    pred = clf.predict(features_test_scaled)\n",
    "\n",
    "    # Classifier scores\n",
    "    precision_score_gnb = precision_score(pred, labels_test, average='weighted')\n",
    "    recall_score_gnb = recall_score(pred, labels_test, average='weighted')\n",
    "\n",
    "    print \"Precision score: \", precision_score_gnb\n",
    "    print \"Recall score: \", recall_score_gnb\n",
    "\n",
    "    # Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "    dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "fitGNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score 0.222222222222\n",
      "Precision score:  0.853977968176\n",
      "Recall score:  0.837209302326\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "# GBM #\n",
    "#######\n",
    "    \n",
    "def fitGBM():\n",
    "    '''Fit, predicts, prints scores and dump clf to pickle files for tester.py'''\n",
    "    \n",
    "    clf = GradientBoostingClassifier(random_state=42,\n",
    "                                     min_samples_leaf=6,\n",
    "                                     min_samples_split=20,\n",
    "                                     n_estimators=98,\n",
    "                                     max_features=5,\n",
    "                                     max_depth=5\n",
    "                                    )\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "\n",
    "    # Classifier scores\n",
    "    f1_score_gbm = f1_score(pred, labels_test)\n",
    "    precision_score_gbm = precision_score(pred, labels_test, average='weighted')\n",
    "    recall_score_gbm = recall_score(pred, labels_test, average='weighted')\n",
    "    print \"F1-score\", f1_score_gbm\n",
    "    print \"Precision score: \", precision_score_gbm\n",
    "    print \"Recall score: \", recall_score_gbm\n",
    "    \n",
    "    # returns the following in tester.py: Accuracy: 0.82931\tPrecision: 0.42724\tRecall: 0.32150\tF1: 0.36690\tF2: 0.33824\n",
    "\t# Total predictions: 13000\tTrue positives:  643\tFalse positives:  862\tFalse negatives: 1357\tTrue negatives: 10138\n",
    "\n",
    "    # Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "    dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "def tuneGBM():\n",
    "    '''Identifies optimal params for GBM to be used in fit function'''\n",
    "    \n",
    "    clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "    params = {'learning_rate':np.linspace(0.1, 0.001, num=100),\n",
    "                  'n_estimators':np.arange(1, 150, 1),\n",
    "                  'max_depth':np.arange(1, 50, 1),\n",
    "                  'max_features':np.arange(1, 20, 1),\n",
    "                  'min_samples_split':np.arange(2, 20, 1),\n",
    "                  'min_samples_leaf':np.arange(1, 20, 1)\n",
    "             }\n",
    "    clf_gbrt_rscv = RandomizedSearchCV(clf, param_distributions=params, cv=cv, n_iter=100, scoring='f1', n_jobs=-1, verbose=1)\n",
    "    clf_gbrt_rscv.fit(features_train_scaled, labels_train)\n",
    "\n",
    "    print clf_gbrt_rscv.best_params_\n",
    "    print clf_gbrt_rscv.best_score_    \n",
    "    \n",
    "fitGBM()\n",
    "#tuneGBM()\n",
    "\n",
    "#Fitting GBM with the followingn features:\n",
    "\n",
    "#features_list = ['poi', 'salary', 'deferral_payments', 'total_payments',\n",
    "#                'loan_advances', 'bonus', 'restricted_stock_deferred',\n",
    "#                'deferred_income', 'total_stock_value', 'expenses']\n",
    "# Precision: 0.42724\tRecall: 0.32150\tF1: 0.36690\n",
    "\n",
    "#features_list = ['poi', 'salary', 'deferral_payments', 'total_payments',\n",
    "#                'loan_advances', 'bonus', 'restricted_stock_deferred',\n",
    "#                'deferred_income', 'total_stock_value']\n",
    "# Precision: 0.55044\tRecall: 0.34650\tF1: 0.42528\n",
    "\n",
    "# features_list = ['poi', 'salary', 'deferral_payments', 'total_payments',\n",
    "#                'loan_advances', 'bonus', 'restricted_stock_deferred',\n",
    "#                'deferred_income']\n",
    "# Precision: 0.48804\tRecall: 0.27550\tF1: 0.35219\n",
    "\n",
    "# features_list = ['poi', 'salary', 'deferral_payments', 'total_payments',\n",
    "#                  'loan_advances', 'bonus', 'restricted_stock_deferred']\n",
    "# Precision: 0.44126\tRecall: 0.31550\tF1: 0.36793\n",
    "\n",
    "# features_list = ['poi', 'salary', 'deferral_payments', 'total_payments',\n",
    "#                  'loan_advances', 'bonus']\n",
    "# Precision: 0.42724\tRecall: 0.32150\tF1: 0.36690\n",
    "\n",
    "# features_list = ['poi', 'salary', 'deferral_payments', 'total_payments',\n",
    "#                'loan_advances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  0.846756425949\n",
      "Recall score:  0.860465116279\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# AdaBoost #\n",
    "############\n",
    "\n",
    "def fitAda():\n",
    "    '''Fit, predicts, prints scores and dump clf to pickle files for tester.py'''\n",
    "    \n",
    "    clf = AdaBoostClassifier(random_state=42, \n",
    "                             n_estimators=95, \n",
    "                             learning_rate=0.11399999999999999, \n",
    "                             algorithm='SAMME.R'\n",
    "                            )\n",
    "    clf.fit(features_train_scaled, labels_train)\n",
    "    pred = clf.predict(features_test_scaled)\n",
    "\n",
    "    # Classifier scores\n",
    "    precision_score_ada = precision_score(pred, labels_test, average='weighted')\n",
    "    recall_score_ada = recall_score(pred, labels_test, average='weighted')\n",
    "\n",
    "    print \"Precision score: \", precision_score_ada\n",
    "    print \"Recall score: \", recall_score_ada\n",
    "\n",
    "    # Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "    dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "def tuneAda():\n",
    "    '''Identifies optimal params for AdaBoost to be used in fit function'''\n",
    "    \n",
    "    clf = AdaBoostClassifier(random_state=42)\n",
    "    params = {\n",
    "        'n_estimators':np.arange(1, 200, 1),\n",
    "        'learning_rate':np.linspace(1.0, 0.001, num=1000),\n",
    "        'algorithm':['SAMME', 'SAMME.R']\n",
    "    }\n",
    "\n",
    "    clf_ada_rscv = RandomizedSearchCV(clf, param_distributions=params, n_iter=50, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
    "    clf_ada_rscv.fit(features_train_scaled, labels_train)\n",
    "    \n",
    "    print clf_ada_rscv.best_params_\n",
    "    print clf_ada_rscv.best_score_\n",
    "    \n",
    "    # f1 score using all features > 0 feature importances:\n",
    "    # {'n_estimators': 120, 'learning_rate': 0.18599999999999994, 'algorithm': 'SAMME.R'}\n",
    "    # 0.30261037296\n",
    "\n",
    "    # f1 score using top 7 features with > 0 feature importances:\n",
    "    # {'n_estimators': 71, 'learning_rate': 0.18199999999999994, 'algorithm': 'SAMME.R'}\n",
    "    # 0.307384648685\n",
    "\n",
    "    # f1 score using top 4 features with > 0 feature importances:\n",
    "    # {'n_estimators': 95, 'learning_rate': 0.11399999999999999, 'algorithm': 'SAMME.R'}\n",
    "    # 0.309828543679\n",
    "\n",
    "    # f1 score using top 3 features with > 0 feature importances:\n",
    "    # {'n_estimators': 102, 'learning_rate': 0.125, 'algorithm': 'SAMME.R'}\n",
    "    # 0.309473709624\n",
    "\n",
    "\n",
    "fitAda()\n",
    "#tuneAda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  1.0\n",
      "Recall score:  0.883720930233\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Decision Tree #\n",
    "#################\n",
    "\n",
    "def fitTree():\n",
    "    '''Fit, predicts, prints scores and dump clf to pickle files for tester.py'''\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier(random_state=42, \n",
    "                                      criterion='gini', \n",
    "                                      max_depth=17, \n",
    "                                      max_features=18, \n",
    "                                      class_weight='balanced', \n",
    "                                      splitter='random', \n",
    "                                      min_samples_leaf=14, \n",
    "                                      min_samples_split=63\n",
    "                                     )\n",
    "    \n",
    "    clf.fit(features_train_scaled, labels_train)\n",
    "    pred = clf.predict(features_test_scaled)\n",
    "\n",
    "    # Classifier scores\n",
    "    precision_score_tree = precision_score(pred, labels_test, average='weighted')\n",
    "    recall_score_tree = recall_score(pred, labels_test, average='weighted')\n",
    "\n",
    "    print \"Precision score: \", precision_score_tree\n",
    "    print \"Recall score: \", recall_score_tree\n",
    "\n",
    "    # Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "    dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "    \n",
    "def tuneTree():\n",
    "    '''Identifies optimal params for Tree to be used in fit function'''   \n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "    clf_tree_rscv = RandomizedSearchCV(clf, param_distributions=parameters, cv=70, n_iter=80, scoring='precision', n_jobs=-1, verbose=1)\n",
    "    clf_tree_rscv.fit(features_train, labels_train)\n",
    "\n",
    "    print clf_tree_rscv.best_params_\n",
    "    print clf_tree_rscv.best_score_\n",
    "\n",
    "    # {'splitter': 'random', 'min_samples_leaf': 14, 'max_features': 18, 'criterion': 'gini', 'min_samples_split': 49, 'max_depth': 17, 'class_weight': 'balanced'}\n",
    "    # 0.25\n",
    "\n",
    "fitTree()\n",
    "#tuneTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  1.0\n",
      "Recall score:  0.883720930233\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# KNearest Neighbors #\n",
    "######################\n",
    "\n",
    "def fitKNN():\n",
    "    '''Fit, predicts, prints scores and dump clf to pickle files for tester.py'''\n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(features_train_scaled, labels_train)\n",
    "    pred = clf.predict(features_test_scaled)\n",
    "\n",
    "    # Classifier scores\n",
    "    precision_score_knn = precision_score(pred, labels_test, average='weighted')\n",
    "    recall_score_knn = recall_score(pred, labels_test, average='weighted')\n",
    "\n",
    "    print \"Precision score: \", precision_score_knn\n",
    "    print \"Recall score: \", recall_score_knn\n",
    "\n",
    "    # Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "    dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "def tuneKNN():    \n",
    "    '''Identifies optimal params for KNN to be used in fit function'''   \n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    params = {\n",
    "        'p':[1, 2],\n",
    "        'n_neighbors':np.arange(1, 50, 1),\n",
    "        'weights':['uniform', 'distance'],\n",
    "        'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'leaf_size':np.arange(10, 50, 1),\n",
    "    }\n",
    "\n",
    "    clf_knn_rscv = RandomizedSearchCV(clf, param_distributions=params, cv=cv, n_iter=50, scoring='f1', n_jobs=-1, verbose=1)\n",
    "    clf_knn_rscv.fit(features_train_scaled, labels_train)\n",
    "\n",
    "\n",
    "    print clf_knn_rscv.best_params_\n",
    "    print clf_knn_rscv.best_score_\n",
    "\n",
    "fitKNN()\n",
    "#tuneKNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  0.933659730722\n",
      "Recall score:  0.906976744186\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "# SVC #\n",
    "#######\n",
    "\n",
    "def fitSVC():\n",
    "    '''Fit, predicts, prints scores and dump clf to pickle files for tester.py'''    \n",
    "    \n",
    "    clf = SVC(random_state=42, \n",
    "              kernel='sigmoid', \n",
    "              C=188.24569042635585, \n",
    "              gamma=0.045051338986761162, \n",
    "              class_weight=None\n",
    "             )\n",
    "    clf.fit(features_train_scaled, labels_train)\n",
    "    pred = clf.predict(features_test_scaled)\n",
    "\n",
    "    # Classifier scores\n",
    "    precision_score_svc = precision_score(pred, labels_test, average='weighted')\n",
    "    recall_score_svc = recall_score(pred, labels_test, average='weighted')\n",
    "    \n",
    "    print \"Precision score: \", precision_score_svc\n",
    "    print \"Recall score: \", recall_score_svc\n",
    "    \n",
    "    # Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "    dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "def tuneSVC():\n",
    "    '''Identifies optimal params for SVC to be used in fit function'''\n",
    "    \n",
    "    clf = SVC(random_state=42)\n",
    "    params = {'C': scipy.stats.expon(scale=100), \n",
    "              'gamma': scipy.stats.expon(scale=.1), \n",
    "              'kernel':['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "              'class_weight': [None, 'balanced']\n",
    "             }\n",
    "    \n",
    "    clf_svc_rscv = RandomizedSearchCV(clf, param_distributions=params, cv=cv,n_iter=20, scoring='f1_weighted', verbose=2, n_jobs=-1)\n",
    "    clf_svc_rscv.fit(features_train_scaled, labels_train)\n",
    "\n",
    "    print clf_svc_rscv.best_params_\n",
    "    print clf_svc_rscv.best_score_\n",
    "\n",
    "    # {'kernel': 'sigmoid', 'C': 188.24569042635585, 'gamma': 0.045051338986761162, 'class_weight': None}\n",
    "    # 0.839949126647\n",
    "\n",
    "fitSVC()\n",
    "#tuneSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  0.701223990208\n",
      "Recall score:  0.744186046512\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Random Forest #\n",
    "#################\n",
    "\n",
    "def fitRF():\n",
    "    '''Fit, predicts, prints scores and dump clf to pickle files for tester.py'''    \n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=42, \n",
    "                                 n_estimators=1, \n",
    "                                 min_samples_leaf=2, \n",
    "                                 min_samples_split=2, \n",
    "                                 max_depth=31\n",
    "                                )\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "\n",
    "    precision_score_rf = precision_score(pred, labels_test, average='weighted')\n",
    "    recall_score_rf = recall_score(pred, labels_test, average='weighted')\n",
    "\n",
    "    print \"Precision score: \", precision_score_rf\n",
    "    print \"Recall score: \", recall_score_rf\n",
    "\n",
    "    # Dumping classifier, my_dataset and features_list as .pkl files to be used in tester.py\n",
    "    dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "def tuneRF():\n",
    "    '''Identifies optimal params for RF to be used in fit function'''\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    params = {\n",
    "        'n_estimators':np.arange(1, 200, 1),\n",
    "        'min_samples_leaf':np.arange(1, 20, 1),\n",
    "        'min_samples_split':np.arange(2, 20, 1),\n",
    "        'max_depth':np.arange(1, 40, 1),\n",
    "    }\n",
    "    clf_rf_rscv = RandomizedSearchCV(clf, cv=cv, n_iter=50, param_distributions=params, scoring='precision', verbose=1, n_jobs=-1)\n",
    "    clf_rf_rscv.fit(features_train, labels_train)\n",
    "\n",
    "    print clf_rf_rscv.best_params_\n",
    "    print clf_rf_rscv.best_score_\n",
    "\n",
    "    # {'n_estimators': 1, 'min_samples_split': 2, 'max_depth': 31, 'min_samples_leaf': 2}\n",
    "    # 0.21\n",
    "\n",
    "fitRF()\n",
    "#tuneRF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  [relevant rubric items: “data exploration”, “outlier investigation”]\n",
    "\n",
    ">Machine learning is powerful at predicting whether a certain outcome is likely to happen (classification) or continuous numbers (regression). In this example where we are asked to predict that a person is a POI (classification) and we have features such as salary, bonus, stock (financial) as well as how many emails they have sent/received (count) we can use such features to learn if these help us predict whether people are POIs or not.\n",
    "\n",
    "> There were 146 rows of data pre-cleaning and 18 POIs and 126 Non-POIs in the dataset.\n",
    "\n",
    "> I have removed 4 outliers from data_dict and they are as follows: \n",
    "'TOTAL', 'THE TRAVEL AGENCY IN THE PARK','BANNANTINE JAMES M','GRAY RODNEY'. I have removed the first two because they don't correspond to an employee, one is a column sum while the other looks to be a company they may have used its services at some point. The final two are outliers when studying salary: perhaps they were consultants or office cleaners because their salaries were 477 USD per year for Bannantine while Gray earned 6k USD over a year. Those are nowhere near what Enron pays for its employees and only add noise to any model.\n",
    "\n",
    "2.What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “intelligently select features”, “properly scale features”]\n",
    "\n",
    ">As part of the EDA I looked at feature importances to understand which features were important and which weren't useful to include in my machine learning algorithms. I took all features which had an importance > 0 because if a feature has no variance it will only make my model more complex and therefore overfit to the training data at hand and won't generalise well. In machine learning, a simple model is preferred over a more complex one for that reason. Below are the feature importances for all features   \n",
    ">\n",
    "  1.  feature: salary (0.21274406496)\n",
    "  2.  feature: deferral_payments (0.189106111008)\n",
    "  3.  feature: total_payments (0.177991452991)\n",
    "  4.  feature: loan_advances (0.0751856363847)\n",
    "  5.  feature: bonus (0.0660231271996)\n",
    "  6.  feature: restricted_stock_deferred (0.0)\n",
    "  7.  feature: deferred_income (0.0)\n",
    "  8.  feature: total_stock_value (0.0)\n",
    "  9.  feature: expenses (0.0)\n",
    "  10.  feature: exercised_stock_options (0.0)\n",
    "  11.  feature: other (0.0)\n",
    "  12.  feature: long_term_incentive (0.0)\n",
    "  13.  feature: restricted_stock (0.0)\n",
    "  14.  feature: director_fees (0.0)\n",
    "  15.  feature: to_messages (0.0)\n",
    "  16.  feature: from_poi_to_this_person (0.0)\n",
    "  17.  feature: from_messages (0.0)\n",
    "  18.  feature: from_this_person_to_poi (0.0)\n",
    "\n",
    "> In the GBM cell in this notebook I have commented out the precision, recall and f1 scores of several feature selections and identified the followingn features to give the highest scores: #features_list = 'poi', 'salary','deferral_payments','total_payments','loan_advances','bonus','restricted_stock_deferred','deferred_income', 'total_stock_value'\n",
    "Precision: 0.55044\tRecall: 0.34650\tF1: 0.42528\n",
    "\n",
    "> I have created my own feature bonus_salary_ratio which is bonus / salary based on the rationale that someone who has a high salary is likely also to have a high bonus. The feature itself had a feature importance greater than 0 (0.0660231271996) but when I ran GBM using the new feature my recall score dropped below the .3 threshold so I have removed it. Interestingly, if I remove both salary and bonus the feature importance of bonus_salary_ratio jumps up significantly but still doesn't improve my models performance compared to using salary and bonus.\n",
    "\n",
    "> I have trained my models on both scaled as well as unscaled training data and had the best precision and recall score when I trained on unscaled features - at least for my GBM which has the highest accuracy scores.\n",
    "\n",
    ">As mentioned earlier I have decided to include any feature with a score > 0 because it is preferable to keep a model as simple as possible to avoid overfitting, i.e. if a model can use fewer features without dropping in its accuracy metrics then that's preferable to a model that has more features with the same score since that won't generalise as well on new data.\n",
    "\n",
    "3.What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]\n",
    "\n",
    "> I ended it up using a GBM with the following params found through RandomizedSearchCV: \n",
    "> GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    ">              learning_rate=0.1, loss='deviance', max_depth=5,\n",
    ">              max_features=5, max_leaf_nodes=None,\n",
    ">              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    ">              min_samples_leaf=6, min_samples_split=20,\n",
    ">              min_weight_fraction_leaf=0.0, n_estimators=98,\n",
    ">              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
    ">              warm_start=False). \n",
    "\n",
    "> I tried SVC, AdaBoost, KNN, DecisionTree, GaussianNB and Random Forest but none returned scores above .3 for both precision and recall. Even when I fine-tuned the parameters using RanomizedSearchCV for all of the above models. For SVC, I would often get an error due to trying to divide by 0 and struggled with even getting the model to work.\n",
    "\n",
    "4.What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).  [relevant rubric items: “discuss parameter tuning”, “tune the algorithm”]\n",
    "\n",
    "> Tuning the parameters of an algorithm is really customising the model to match your dataset. For some of the parameters such as min_samples_split there is a trade-off between performance and accuracy: a high sample_split means you are avoiding over-fitting whereas a too high value means you are underfitting. Likewise with the learning_rate, if you give it too high a value you risk it might miss the optimal point whereas if it's too low it will take too long to converge and reach the local minima. For GBM I have tuned the following metrics: n_estimators, max_depth, max_features, learning_rate, min_samples_split, min_samples_leaf and of course set random_state to 42 so my results can be reproduced.\n",
    "         \n",
    "> and for SVC I have used the following params:\n",
    "\n",
    "> params = {'C': scipy.stats.expon(scale=100), \n",
    "          'gamma': scipy.stats.expon(scale=.1), \n",
    "          'kernel':['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "          'class_weight': [None, 'balanced']\n",
    "         }\n",
    "\n",
    "5.What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric items: “discuss validation”, “validation strategy”]\n",
    "\n",
    "> Validation, also known as cross-validation. It is used to prevent over-fitting to the training data. If you don't use cross-validation you risk overfitting your model to the training dataset which means it won't be able to perform well on un-seen new data because it is unable to generalise well. CV works by splitting the training dataset into smaller sets which the model is evaluated on and for each fold it will then return the score average accuracy score from all of the folds. CV is especially important with imbalanced classes as it increases the probability that your CV folds are more representative of the data.\n",
    "\n",
    "> I have used StratifiedShuffleSplit due to the imbalanced classes present in labels (i.e. only 18 POIs). SSS takes random rows from the dataset to increase the likelihood of including the imbalanced classes.\n",
    "\n",
    "6.Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]\n",
    "\n",
    "> As mentioned above my best performing model was a GBM model. When I ran the tester.py I got the following scores:Precision: 0.47601\tRecall: 0.31250. For precision score, it measures how accurate our model was at predicting a POI out of both POIs + those that weren't. Such a metric is important as we do not want to label an employee for being a POI when in fact they weren't - we may shame them unjustly in the public when they haven't done anything wrong. On the other hand, recall score measures how accurate our model was at predicting a POI out of both POI + whether someone wasn't a POI when they in fact were. This is less important compared to precision score due to the concept of being innocent until proven guilty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
